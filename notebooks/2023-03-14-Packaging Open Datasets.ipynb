{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packaging Open Datasets\n",
    "\n",
    "Anyone that has worked with datasets has, at some point, wished for a package manager for datasets. A \"Git for Data\". Many projects have tried and many have died in the process. \n",
    "\n",
    "This notebook walks over a simple and effective way we could create Datasets Packages using the [Frictionless Data](https://frictionlessdata.io/) library and specs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install frictionless --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "duckdb.sql(\n",
    "    \"\"\"\n",
    "    INSTALL httpfs;\n",
    "    LOAD httpfs;\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frictionless Data Packages\n",
    "\n",
    "Frictionless Data Packages can be simplified to a JSON/YAML file with some metadata on it. Let's inspect an exising package, the [CO2 PPM - Trends in Atmospheric Carbon Dioxide](https://datahub.io/core/co2-ppm) Package. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frictionless import Package, Resource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_package = Package(\"https://datahub.io/core/co2-ppm/datapackage.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$frictionless: package/v2\n",
      "name: co2-ppm\n",
      "title: CO2 PPM - Trends in Atmospheric Carbon Dioxide\n",
      "description: 'Data are sourced from the US Government''s Earth System Research Laboratory,\n",
      "  Global Monitoring Division. Two main series are provided: the Mauna Loa series (which\n",
      "  has the longest continuous series since 1958) and a Global Average series (a global\n",
      "  average over marine surface sites).'\n",
      "homepage: http://www.esrl.noaa.gov/gmd/ccgg/trends\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(co2_package.to_yaml()[:449])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages have Resources, which are the tables and files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "co2_resource = co2_package.get_table_resource(\"co2-mm-mlo\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these resources are just files, we can work with them as we would with any other file. \n",
    "In this case, we'll use DuckDB to run SQL queries on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────┬──────────────┬─────────┬──────────────┬────────┬────────────────┐\n",
       "│  Date   │ Decimal Date │ Average │ Interpolated │ Trend  │ Number of Days │\n",
       "│ varchar │    double    │ double  │    double    │ double │     int64      │\n",
       "├─────────┼──────────────┼─────────┼──────────────┼────────┼────────────────┤\n",
       "│ 2018-09 │     2018.708 │  405.51 │       405.51 │ 409.02 │             29 │\n",
       "│ 2018-08 │     2018.625 │  406.99 │       406.99 │  408.9 │             30 │\n",
       "│ 2018-07 │     2018.542 │  408.71 │       408.71 │ 408.32 │             27 │\n",
       "│ 2018-06 │     2018.458 │  410.79 │       410.79 │ 408.49 │             29 │\n",
       "│ 2018-05 │     2018.375 │  411.24 │       411.24 │ 407.91 │             24 │\n",
       "└─────────┴──────────────┴─────────┴──────────────┴────────┴────────────────┘"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(f\"select * from '{co2_resource.path}' order by Date desc limit 5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to the Frictionless Data library, we can easily load the data in our preferred format and start exploring it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygwalker as pyg\n",
    "pyg.walk(co2_resource.to_pandas())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packaging External Datasets\n",
    "\n",
    "Now, lets try packaging an existing dataset using the Frictionless Specs. In this case, the Global Monitoring Laboratory CO2 trend. \n",
    "\n",
    "They're maintaining the CSV. We're going to just package it so people can benefit from the Frictionless ecosystem.\n",
    "\n",
    "To do that, we create a `Resource` and then the `Package` with the `Resource` as a resource."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_resource = Resource(\n",
    "    \"https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'variableTypes': {},\n",
       " 'notNullRows': 783,\n",
       " 'rowsWithNullValues': 22,\n",
       " 'fieldStats': {},\n",
       " 'averageRecordSizeInBytes': 47.06335403726708,\n",
       " 'timeTaken': 1.969,\n",
       " 'md5': '63416e17fb2058f09c213e04134c731b',\n",
       " 'sha256': 'f8f2530b9886316d765b4eff3ff95e042c56a7c61ad79cae93c70b4af664efca',\n",
       " 'bytes': 37886,\n",
       " 'fields': 3,\n",
       " 'rows': 805}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "external_resource.analyze()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest possible Package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_package = Package(\n",
    "    name=\"co2-mm-mlo\",\n",
    "    title=\"Trends in Atmospheric Carbon Dioxide\",\n",
    "    resources=[external_resource],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────┬───────┬──────────────┬─────────┬────────────────┬───────┬────────┬────────┐\n",
       "│ year  │ month │ decimal date │ average │ deseasonalized │ ndays │  sdev  │  unc   │\n",
       "│ int64 │ int64 │    double    │ double  │     double     │ int64 │ double │ double │\n",
       "├───────┼───────┼──────────────┼─────────┼────────────────┼───────┼────────┼────────┤\n",
       "│  2023 │     1 │    2023.0417 │  419.47 │         419.14 │    31 │    0.4 │   0.14 │\n",
       "│  2023 │     2 │     2023.125 │  420.41 │         419.49 │    25 │   0.64 │   0.25 │\n",
       "│  2022 │     1 │    2022.0417 │  418.19 │         417.86 │    29 │   0.73 │   0.26 │\n",
       "│  2022 │     2 │     2022.125 │  419.28 │         418.36 │    27 │   0.92 │   0.34 │\n",
       "│  2022 │     3 │    2022.2083 │  418.81 │         417.32 │    30 │   0.78 │   0.27 │\n",
       "└───────┴───────┴──────────────┴─────────┴────────────────┴───────┴────────┴────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(f\"select * from '{external_resource.path}' order by year desc limit 5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, for this to become an actual package it needs to be published somewhere. Data Packages are just URLs with a `datapackage.json/yaml` file in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$frictionless: package/v2\n",
      "name: co2-mm-mlo\n",
      "title: Trends in Atmospheric Carbon Dioxide\n",
      "resources:\n",
      "  - name: co2_mm_mlo\n",
      "    type: table\n",
      "    path: https://gml.noaa.gov/webdata/ccgg/trends/co2/co2_mm_mlo.csv\n",
      "    scheme: https\n",
      "    format: csv\n",
      "    mediatype: text/csv\n",
      "    encoding: utf-8\n",
      "    dialect:\n",
      "      headerRows:\n",
      "        - 32\n",
      "    schema:\n",
      "      fields:\n",
      "        - name: '# of the GML data'\n",
      "          type: string\n",
      "        - name: namely well documented model code\n",
      "          type: string\n",
      "        - name: transport\n",
      "          type: string\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(external_package.to_yaml(\"/tmp/datapackage.yaml\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's upload it to a random temporal hosting service, and then use the package as other users would use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100   577  100    43  100   534     63    793 --:--:-- --:--:-- --:--:--   856\n"
     ]
    }
   ],
   "source": [
    "%%bash --out temp_file_path\n",
    "curl --upload-file /tmp/datapackage.yaml https://transfer.sh/datapackage.yaml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The package is now published at the `temp_file_path` URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://transfer.sh/xEGOti/datapackage.yaml'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_external_package = Package(temp_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────┬───────┬──────────────┬─────────┬────────────────┬───────┬────────┬────────┐\n",
       "│ year  │ month │ decimal date │ average │ deseasonalized │ ndays │  sdev  │  unc   │\n",
       "│ int64 │ int64 │    double    │ double  │     double     │ int64 │ double │ double │\n",
       "├───────┼───────┼──────────────┼─────────┼────────────────┼───────┼────────┼────────┤\n",
       "│  2023 │     1 │    2023.0417 │  419.47 │         419.14 │    31 │    0.4 │   0.14 │\n",
       "│  2023 │     2 │     2023.125 │  420.41 │         419.49 │    25 │   0.64 │   0.25 │\n",
       "│  2022 │     1 │    2022.0417 │  418.19 │         417.86 │    29 │   0.73 │   0.26 │\n",
       "│  2022 │     2 │     2022.125 │  419.28 │         418.36 │    27 │   0.92 │   0.34 │\n",
       "│  2022 │     3 │    2022.2083 │  418.81 │         417.32 │    30 │   0.78 │   0.27 │\n",
       "└───────┴───────┴──────────────┴─────────┴────────────────┴───────┴────────┴────────┘"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(\n",
    "    f\"select * from '{remote_external_package.get_resource('co2_mm_mlo').path}' order by year desc limit 5\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to package an external dataset. Wouldn't it be cool if we could create some sort of collections? Enter `Catalog`s."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Catalog\n",
    "\n",
    "[A Catalog](https://framework.frictionlessdata.io/docs/framework/catalog.html) is a collection of Data Packages. It's a way to group them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frictionless import Catalog, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = Dataset(name=\"co2-mm-mlo\", package=co2_package)\n",
    "d2 = Dataset(name=\"external-co2-mm-mlo\", package=remote_external_package)\n",
    "catalog = Catalog(datasets=[d1, d2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(catalog.to_yaml())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One could imagine lots of tooling around this, a simple one would be a way for a database to understand the Catalog and allow SQL queries to be run on the packages.\n",
    "\n",
    "Let's try to create a simple DuckDB Catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added co2-mm-mlo_csv table.\n",
      "Added co2-annmean-mlo_csv table.\n",
      "Added co2-gr-mlo_csv table.\n",
      "Added co2-mm-gl_csv table.\n",
      "Added co2-annmean-gl_csv table.\n",
      "Added co2-gr-gl_csv table.\n",
      "Added co2-mm-mlo table.\n",
      "Added co2-annmean-mlo table.\n",
      "Added co2-gr-mlo table.\n",
      "Added co2-mm-gl table.\n",
      "Added co2-annmean-gl table.\n",
      "Added co2-gr-gl table.\n",
      "Added co2_mm_mlo table.\n"
     ]
    }
   ],
   "source": [
    "for c in catalog.datasets:\n",
    "    for resource in c.package.resources:\n",
    "        if resource.type == \"table\" and resource.format == \"csv\":\n",
    "            duckdb.sql(\n",
    "                f\"\"\"\n",
    "            create view if not exists {resource.name.replace('-', '_')} as \n",
    "            select * from '{resource.path}';\n",
    "            \"\"\"\n",
    "            )\n",
    "            print(f\"Added {resource.name} table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌─────────────────────┐\n",
       "│        name         │\n",
       "│       varchar       │\n",
       "├─────────────────────┤\n",
       "│ co2_annmean_gl      │\n",
       "│ co2_annmean_gl_csv  │\n",
       "│ co2_annmean_mlo     │\n",
       "│ co2_annmean_mlo_csv │\n",
       "│ co2_gr_gl           │\n",
       "│ co2_gr_gl_csv       │\n",
       "│ co2_gr_mlo          │\n",
       "│ co2_gr_mlo_csv      │\n",
       "│ co2_mm_gl           │\n",
       "│ co2_mm_gl_csv       │\n",
       "│ co2_mm_mlo          │\n",
       "│ co2_mm_mlo_csv      │\n",
       "├─────────────────────┤\n",
       "│       12 rows       │\n",
       "└─────────────────────┘"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(\n",
    "    \"\"\"\n",
    "SHOW TABLES;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, all the datasets are a SQL away. Data is only readed when needed and this could even work in a WASM environment (using the [JSON extension](https://duckdb.org/docs/extensions/json.html))!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────┬─────────────────┬─────────────┬─────────┬──────────────┬─────────┬────────┬───────┐\n",
       "│ Year  │ Annual Increase │ Uncertainty │  Date   │ Decimal Date │ Average │ Trend  │ year  │\n",
       "│ int64 │     double      │   double    │ varchar │    double    │ double  │ double │ int64 │\n",
       "├───────┼─────────────────┼─────────────┼─────────┼──────────────┼─────────┼────────┼───────┤\n",
       "│  2015 │            3.02 │        0.11 │ 2018-03 │     2018.208 │  408.57 │ 406.92 │  2018 │\n",
       "│  2015 │            3.02 │        0.11 │ 2018-04 │     2018.292 │  408.88 │ 407.06 │  2018 │\n",
       "│  2015 │            3.02 │        0.11 │ 2018-05 │     2018.375 │  408.75 │ 407.14 │  2018 │\n",
       "│  2015 │            3.02 │        0.11 │ 2018-06 │     2018.458 │  407.86 │ 407.34 │  2018 │\n",
       "│  2015 │            3.02 │        0.11 │ 2018-07 │     2018.542 │  406.39 │ 407.74 │  2018 │\n",
       "└───────┴─────────────────┴─────────────┴─────────┴──────────────┴─────────┴────────┴───────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duckdb.sql(\n",
    "    \"\"\"\n",
    "with base as (\n",
    "    select \n",
    "        *, \n",
    "    date_part('year', strptime(Date, '%Y-%m')) as year \n",
    "    from co2_mm_gl order by Date desc limit 5\n",
    ")\n",
    "\n",
    "select * from co2_gr_mlo as co2\n",
    "left join base on co2.year = base.year - 3\n",
    "where Date is not null\n",
    "order by co2.Year \n",
    "desc limit 5;\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packaging Data from External Services\n",
    "\n",
    "Frictionless allow to create plugins to package external services. In this case, we'll package HuggingFace datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from frictionless import Plugin\n",
    "from frictionless import Loader, Parser\n",
    "from frictionless import system\n",
    "from frictionless.schemes import RemoteLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuggingFacePlugin(Plugin):\n",
    "    def create_parser(self, resource):\n",
    "        if resource.format == \"huggingface\":\n",
    "            resource.datatype = \"table\"\n",
    "            return HuggingFaceParser(resource)\n",
    "    \n",
    "    def detect_resource(self, resource: Resource):\n",
    "        if resource.format == \"huggingface\":\n",
    "            resource.datatype = resource.datatype or \"table\"\n",
    "\n",
    "class HuggingFaceParser(Parser):\n",
    "\n",
    "    def read_cell_stream_create(self):\n",
    "        dataset = load_dataset(self.resource.path, split='train')\n",
    "        for i in dataset.to_iterable_dataset():\n",
    "            yield list(i.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "system.register('huggingface', HuggingFacePlugin())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_resource = Resource('rotten_tomatoes', format='huggingface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset rotten_tomatoes (/home/vscode/.cache/huggingface/datasets/rotten_tomatoes/default/1.0.0/40d411e45a6ce3484deed7cc15b82a53dad9a72aafd9f86f8f227134bec5ca46)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7915</th>\n",
       "      <td>it's a bad action movie because there's no roo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7529</th>\n",
       "      <td>like its script , which nurses plot holes gapi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8103</th>\n",
       "      <td>there's a neat twist , subtly rendered , that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6688</th>\n",
       "      <td>begins as a promising meditation on one of ame...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6252</th>\n",
       "      <td>mattei is tiresomely grave and long-winded , a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     the rock is destined to be the 21st century's new \" conan \" and that he's going to make a splash even greater than arnold schwarzenegger , jean-claud van damme or steven segal .  \\\n",
       "7915  it's a bad action movie because there's no roo...                                                                                                                                  \n",
       "7529  like its script , which nurses plot holes gapi...                                                                                                                                  \n",
       "8103  there's a neat twist , subtly rendered , that ...                                                                                                                                  \n",
       "6688  begins as a promising meditation on one of ame...                                                                                                                                  \n",
       "6252  mattei is tiresomely grave and long-winded , a...                                                                                                                                  \n",
       "\n",
       "      1  \n",
       "7915  0  \n",
       "7529  0  \n",
       "8103  0  \n",
       "6688  0  \n",
       "6252  0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf_resource.to_pandas().sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_package = Package(\n",
    "    name=\"hf-dataset\",\n",
    "    title=\"Hugging Face Dataset\",\n",
    "    resources=[hf_resource],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$frictionless: package/v2\n",
      "name: hf-dataset\n",
      "title: Hugging Face Dataset\n",
      "resources:\n",
      "  - name: rotten_tomatoes\n",
      "    type: table\n",
      "    path: rotten_tomatoes\n",
      "    scheme: file\n",
      "    format: huggingface\n",
      "    schema:\n",
      "      fields:\n",
      "        - name: the rock is destined to be the 21st century's new \" conan \" and that\n",
      "            he's going to make a splash even greater than arnold schwarzenegger ,\n",
      "            jean-claud van damme or steven segal .\n",
      "          type: string\n",
      "        - name: '1'\n",
      "          type: integer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(external_package.to_yaml())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: Fix column names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
